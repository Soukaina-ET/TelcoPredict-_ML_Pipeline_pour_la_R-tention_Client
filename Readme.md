![Python](https://img.shields.io/badge/python-3.10+-blue.svg) ![Status](https://img.shields.io/badge/status-terminÃ©-success.svg)

# Customer Churn Prediction - Telco

Un projet de Machine Learning pour prÃ©dire le risque de dÃ©sabonnement (churn) des clients d'une entreprise de tÃ©lÃ©communications.

## ğŸ“‹ Vue d'ensemble

Ce projet utilise des algorithmes de classification (Random Forest et XGBoost) pour identifier les clients Ã  risque de partir, permettant ainsi Ã  l'entreprise de mettre en place des actions de rÃ©tention ciblÃ©es.

**Dataset**: Telco Customer Churn (IBM Sample)  
**Objectif**: PrÃ©dire si un client va se dÃ©sabonner (Churn = Yes/No)  
**MÃ©trique principale**: AUC-ROC Score

## ğŸ“‚ Structure du projet

```
doc/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py          # Pipeline de prÃ©paration des donnÃ©es
â”‚   â””â”€â”€ view_data.ipynb           # Analyse exploratoire (EDA)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ train_model.py            # EntraÃ®nement des modÃ¨les
â”‚   â””â”€â”€ predict.py                # Scoring de nouveaux clients
â”œâ”€â”€ RÃ©sultats/
â”‚   â”œâ”€â”€ Figure_1.png              # Matrice de confusion
â”‚   â”œâ”€â”€ Figure_2.png              # Importance des features
â”‚   â””â”€â”€ Facteurs_Churn1.png       # Visualisations EDA
â”œâ”€â”€ churn_model_v1.pkl            # ModÃ¨le Random Forest
â”œâ”€â”€ churn_model_xgb_final.pkl     # ModÃ¨le XGBoost (meilleur)
â””â”€â”€ requirements.txt
```

## ğŸš€ Installation

```bash
# Cloner le repository
git clone <votre-repo>
cd doc

# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ“Š Analyse exploratoire (EDA)

Ouvrir le notebook `preprocessing/view_data.ipynb` pour voir:
- Distribution des variables numÃ©riques (tenure, charges)
- DÃ©sÃ©quilibre des classes (26.5% de churn)
- Impact des variables clÃ©s:
  - **Contract**: Les clients "Month-to-month" partent massivement
  - **MonthlyCharges**: Les clients qui paient cher sont plus Ã  risque
  - **Tenure**: Les nouveaux clients (< 6 mois) sont vulnÃ©rables

![Impact du contrat](RÃ©sultats/image.png)

## ğŸ› ï¸ PrÃ©traitement des donnÃ©es

Le fichier `preprocessing/preprocessing.py` contient:

1. **Nettoyage**:
   - Conversion de `TotalCharges` (object â†’ float)
   - Gestion des valeurs manquantes (11 lignes supprimÃ©es)

2. **Feature Engineering**:
   - `Charges_per_Tenure` = TotalCharges / tenure
   - `Total_Services` = Somme des services additionnels
   - `Is_Long_Term` = 1 si tenure > 12 mois

3. **Encodage**:
   - Variables numÃ©riques: StandardScaler
   - Variables catÃ©gorielles: OneHotEncoder

```python
from preprocessing.preprocessing import prepare_data

X_train, X_test, y_train, y_test = prepare_data('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')
```

## ğŸ¯ EntraÃ®nement des modÃ¨les

### Random Forest (baseline)
```bash
python models/train_model.py
```

**RÃ©sultats** (voir code ligne 1-50):
- AUC Score: **0.80**
- PrÃ©cision classe 1 (churn): 58%
- Recall classe 1: 46%

### XGBoost avec GridSearchCV (modÃ¨le final)

HyperparamÃ¨tres optimisÃ©s:
```python
param_grid = {
    'classifier__n_estimators': [100, 200],
    'classifier__learning_rate': [0.01, 0.1],
    'classifier__max_depth': [3, 5]
}
```

**RÃ©sultats** (voir code ligne 51-fin):
- AUC Score: **0.8381** âœ…
- PrÃ©cision classe 1: 64%
- Recall classe 1: 52%

### Optimisation du seuil de dÃ©cision

Au lieu du seuil par dÃ©faut (0.5), nous utilisons **0.37** pour maximiser le recall:
- Permet de capturer **70% des clients qui partent** (vs 52% avant)
- Trade-off: Augmente les faux positifs mais rÃ©duit les pertes de clients

![Courbe Precision-Recall](RÃ©sultats/Figure_2.png)

"Nous avons arbitrÃ© en faveur du Rappel plutÃ´t que de la PrÃ©cision. En abaissant le seuil de dÃ©cision Ã  0.37, nous avons augmentÃ© notre capacitÃ© Ã  dÃ©tecter les clients sur le dÃ©part de 52% Ã  70%. Bien que cela gÃ©nÃ¨re plus de 'fausses alertes', le coÃ»t d'une campagne de rÃ©tention (coupon, appel) est largement infÃ©rieur au coÃ»t d'acquisition d'un nouveau client."
## ğŸ“ˆ Top 5 Features importantes

D'aprÃ¨s l'analyse XGBoost:
1. **Charges_per_Tenure** (0.25) â†’ Ratio prix/anciennetÃ©
2. **TotalCharges** (0.15) â†’ Montant total payÃ©
3. **MonthlyCharges** (0.12) â†’ Facture mensuelle
4. **tenure** (0.10) â†’ AnciennetÃ© client
5. **Contract_Two year** (0.05) â†’ Type de contrat

![Feature Importance](RÃ©sultats/Facteurs_Churn1.png)
## ğŸ’¡ StratÃ©gie de RÃ©tention (Insights Business)

Le modÃ¨le identifie trois leviers majeurs pour rÃ©duire le churn :
1. **Migration de Contrat** : Inciter les clients "Month-to-month" (plus Ã  risque) vers des contrats d'un ou deux ans via des remises ciblÃ©es.
2. **Support Fibre Optique** : La fibre Ã©tant un facteur de churn Ã©levÃ©, amÃ©liorer la qualitÃ© du service technique pour cette catÃ©gorie.
3. **Optimisation du "Charges_per_Tenure"** : Surveiller les clients dont le ratio prix/anciennetÃ© augmente brutalement.

## ğŸ“‹ Prochaines Ã©tapes

- [ ] DÃ©ployer le modÃ¨le avec FastAPI/Flask
- [ ] CrÃ©er un dashboard Streamlit pour le scoring en temps rÃ©el
- [ ] Tester SMOTE pour Ã©quilibrer les classes
- [ ] Ajouter des features temporelles (saisonnalitÃ©)
- [ ] Monitorer le model drift en production



---

**Auteur**: ETTAOUSSI SOUKAINA  
**Contact**: ettaoussisoukaina7@gmail.com
